# ğŸ” Blockchain Analyzer

**Neo4j vs PySpark Performance Comparison for Blockchain Forensics**

A comprehensive blockchain forensics platform that compares graph database (Neo4j) vs big data processing (PySpark) approaches for Ethereum transaction analysis. Built for real-time threat detection, pattern analysis, and performance benchmarking.

## ğŸ¯ Project Overview

This project demonstrates a **hybrid architecture** for blockchain analytics, implementing both Neo4j and PySpark approaches to determine optimal solutions for different forensic scenarios. The system processes real Ethereum data and provides actionable insights for compliance, fraud detection, and network analysis.

## ğŸ—ï¸ Architecture

```
Blockchain Data â†’ Spark ETL â†’ Elasticsearch â†’ Kibana Dashboard
                      â†“
                   Neo4j Graph â† Performance Testing
```

## ğŸš€ Key Features

### ğŸ“Š **Performance Comparison Framework**
- **Real-time benchmarking** between Neo4j and PySpark
- **Operation-specific analysis**: wallet degree, multi-hop traversal, pattern detection
- **Quantitative metrics**: execution time, success rates, resource usage
- **Actionable recommendations** for optimal technology selection

### ğŸ” **Blockchain Forensics**
- **Multi-layer ETL Pipeline**: Bronze â†’ Silver â†’ Gold data refinement
- **Threat Detection**: Chain hopping, smurfing, peel chain patterns
- **Risk Scoring**: Automated suspicious transaction identification
- **Graph Analytics**: Relationship mapping and network flow analysis

### ğŸ“ˆ **Real-time Analytics**
- **Live Data Ingestion**: Infura API integration for real blockchain data
- **Sample Data Generation**: Comprehensive testing without API dependencies
- **Interactive Dashboards**: Kibana visualizations for transaction patterns
- **Alert System**: High-value and suspicious transaction monitoring

### ğŸ› ï¸ **Production Ready**
- **Docker Deployment**: One-command stack setup (Elasticsearch, Kibana, Neo4j)
- **Environment Configuration**: Secure API key management
- **Mock Implementations**: Testing without infrastructure dependencies
- **Comprehensive Logging**: Debug-ready with structured output

## ğŸ† Performance Results

**Benchmark Findings (1000 transactions):**

| Operation | Neo4j Time | PySpark Time | Winner | Speedup |
|------------|---------------|---------------|----------|----------|
| Wallet Degree | 0.0001s | 0.0000s | PySpark | 0.02x |
| Multi-hop (3) | 0.0001s | 0.0078s | **Neo4j** | **73.42x** |
| Suspicious Detection | 0.0002s | 0.0033s | **Neo4j** | **18.88x** |

**ğŸ’¡ Key Insights:**
- **Neo4j excels** at graph traversal and relationship queries
- **PySpark better** for simple aggregations and batch processing
- **Hybrid approach recommended**: Neo4j for real-time, PySpark for batch analytics

## ğŸ› ï¸ Technology Stack

### **Core Technologies**
- **Python 3.10+**: Main application logic
- **Apache PySpark 3.5.0**: Big data processing engine
- **Neo4j 5.15.0**: Graph database for relationship queries
- **Elasticsearch 8.11.0**: Search and analytics backend
- **Kibana 8.11.0**: Visualization dashboard platform

### **Data Sources**
- **Infura API**: Real-time blockchain data
- **Etherscan API**: Enhanced transaction metadata (optional)
- **Sample Generator**: Synthetic data for testing

### **Infrastructure**
- **Docker & Docker Compose**: Containerized deployment
- **GraphFrames 0.6**: Graph processing with Spark
- **Plotly 5.17.0**: Interactive visualizations

## ğŸš€ Quick Start

### **1. Clone & Setup**
```bash
git clone https://github.com/Eng-Zakaria/blockchain-analyzer.git
cd blockchain-analyzer
pip install -r requirements.txt
```

### **2. Configure API Keys**
```bash
python setup_env.py
# Follow prompts for Infura API key (required)
# Etherscan API key optional
```

### **3. Run Analysis**
```bash
# With sample data
python main.py

# With real blockchain data (after API setup)
python main.py
```

### **4. Start Full Stack (Optional)**
```bash
docker-compose up -d
# Access Kibana: http://localhost:5601
# Access Neo4j: http://localhost:7474
```

## ğŸ“Š Project Structure

```
blockchain-analyzer/
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ ğŸ“ core/                    # Spark & Neo4j clients
â”‚   â”œâ”€â”€ ğŸ“ data/                    # Blockchain data sources
â”‚   â”œâ”€â”€ ğŸ“ spark/                   # ETL pipeline implementation
â”‚   â”œâ”€â”€ ğŸ“ comparison/              # Performance testing framework
â”‚   â””â”€â”€ ğŸ“ visualization/            # Kibana dashboard generator
â”œâ”€â”€ ğŸ“ config/                     # Environment configuration
â”œâ”€â”€ ğŸ“ etl/                        # Processed data layers
â”œâ”€â”€ ğŸ³ docker-compose.yml           # Full stack deployment
â”œâ”€â”€ ğŸ“‹ main.py                     # Application entry point
â””â”€â”€ ğŸ“„ README_KIBANA.md           # Kibana documentation
```

## ğŸ¯ Use Cases & Applications

### **ğŸ›ï¸ Compliance & Regulatory**
- **AML/CFT Monitoring**: Automated suspicious transaction detection
- **Regulatory Reporting**: Structured data for compliance teams
- **Risk Assessment**: Wallet behavior profiling and scoring

### **ğŸ” Forensic Investigation**
- **Transaction Tracing**: Multi-hop fund flow analysis
- **Pattern Recognition**: Chain hopping and smurfing detection
- **Network Mapping**: Visual relationship analysis

### **ğŸ’¼ Business Intelligence**
- **DeFi Protocol Analysis**: Smart contract interaction patterns
- **Market Activity**: Transaction volume and gas price trends
- **Wallet Analytics**: User behavior and segmentation

## ğŸ§ª Testing & Development

### **Mock Implementations**
- **SimpleSparkClient**: Pandas-based Spark replacement
- **MockNeo4jClient**: In-memory graph simulation
- **MockElasticsearch**: Local data indexing
- **Sample Data Generator**: Realistic transaction simulation

### **Performance Testing**
- **Automated Benchmarks**: Consistent performance measurement
- **Error Handling**: Graceful degradation testing
- **Resource Monitoring**: Memory and usage tracking

## ï¿½ Interview Talking Points

### **ğŸ¯ Problem Solving**
*"I built a hybrid blockchain forensics platform that compares Neo4j vs PySpark approaches to determine optimal solutions for different forensic scenarios. The system processes real Ethereum data and provides actionable insights for compliance and fraud detection."*

### **ğŸ—ï¸ Architecture Decisions**
*"I implemented a multi-layer ETL pipeline (Bronze â†’ Silver â†’ Gold) to ensure data quality and enable different levels of analysis. The architecture supports both real-time graph queries and batch analytics, allowing us to choose the right tool for each use case."*

### **ğŸ“Š Performance Insights**
*"Through comprehensive benchmarking, I discovered that Neo4j performs 73x better for multi-hop graph traversals, while PySpark excels at simple aggregations. This led to a hybrid approach recommendation for production systems."*

### **ğŸ› ï¸ Technical Challenges**
*"I solved dependency conflicts by creating mock implementations, enabling development without full infrastructure. I also built a Docker deployment system for one-command production setup."*

### **ğŸ” Real-world Impact**
*"The system can process 1000+ transactions in real-time, identify suspicious patterns, and provide interactive dashboards for investigators. This directly addresses compliance needs in the blockchain space."*

## ğŸ”§ Configuration

### **Environment Variables**
```bash
# Required
INFURA_API_KEY=your_infura_key_here

# Optional
ETHERSCAN_API_KEY=your_etherscan_key_here
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_password
```

### **Data Paths**
```bash
ETL_BRONZE_PATH=./etl/bronze    # Raw transaction data
ETL_SILVER_PATH=./etl/silver    # Cleaned & validated data
ETL_GOLD_PATH=./etl/gold        # Enriched analytics data
```

## ğŸš€ Production Deployment

### **Docker Stack**
```bash
# Start all services
docker-compose up -d

# Check status
docker-compose ps

# View logs
docker-compose logs -f
```

### **Services Included**
- **Elasticsearch**: http://localhost:9200
- **Kibana Dashboard**: http://localhost:5601
- **Neo4j Browser**: http://localhost:7474

## ğŸ“š Documentation

- **[Kibana Dashboard Guide](README_KIBANA.md)**: Complete visualization setup
- **[API Documentation](src/)**: Inline code documentation
- **[Docker Setup](docker-compose.yml)**: Infrastructure as code

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push branch: `git push origin feature/amazing-feature`
5. Open Pull Request


---

**ğŸ”— Built for blockchain forensics, compliance, and intelligence analysis.**
